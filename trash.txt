As movies and video games compete to take audiences on more and more outlandish stories, photorealism remains one of the most in-demand skills in 3D today. But if you ask me, the movie that everybody should be studying is Toy Story 4, because Toy Story 4 of all movies gets all the principles of photorealism correct, which is what we're going to be talking about today, the principles and secrets of photorealism, which can be broken down into three categories, light, materials, and optics, starting with light, the most fundamental and important to get right. The easiest when it comes to light is understanding light colour. And you could do worse than basically making all your lights fall within the Kelvin scale. As a basic rule of thumb, most lights in the real world fall within that scale. And in Blender, that's pretty simple. Just add a black body node, and there's your lights. So you can see that the majority of the shots in Toy Story 4 use warm tones for incandescent or sunlight and cool tones for moonlight or skylighting. Falling into the artificial realm with the purples and pinks when they go to the carnival. And as an aside, strict adherence to this black body is used in many productions, like in David Fincher's Bad Travelling short for the Love, Death and Robots episode, whereby he specifically instructed his team to use 1800 Kelvin for the lanterns and 4000 Kelvin for the moonlight. Then it doesn't matter how the shot is graded, because those lights are the correct distance apart, it'll always feel correct. The next and probably the most important, in my opinion, and most underlooked is light falloff. We're all aware that light falls off, you know, over a distance. But I think most people, it's common to underestimate how much falloff there is. So let's say, for example, you've got a character, they're standing underneath a lamp, so close that they could reach up and touch it. If we say that the amount of light that's hitting the head is 100%, what percent do you think is hitting the feet? Think about it for a second. What percentage do you think it is? Who thinks it's 100%? All right, no one. 50%? Around 25%? Around 10%? 5%? Yeah, you guys are closest. 5% or lower. We know that the exact amount actually is 1.2%. Or zero, according to that screen. It's so dark. Yeah, color grading's never the best on projectors. There's some light there. 1.2%. And we know this because of something called the inverse square law, which says that if you take the position of a lamp and arbitrary distance from it, and then you double it, you can calculate the position of that and double it again and again and again all the way down. Now, this isn't important to know. There's no point memorizing this writing a note because the 3D software does this for you. But what's important is to notice, look, I got a laser pointer, ooh. The distance between the first and the second, it drops 75%. But the next one down, it only drops 14%, then 5%, then two, one, one, 0.5, and then finally 0.3. So the same distance, 0.3, 75%. So basically, what you need to remember, light intensity falls sharply from the point where it originates. But the further away, the less fall-off there is, which is why right on his fingertip there, you can see that the light is clipping. But by the time it gets to the knuckles, it's already fallen off drastically. And you can see that the amount of light hitting his thigh is roughly the same amount of light hitting his shin because the further away you are, the less fall-off there is, which is why you could be standing on the tippity top of the Burj Khalifa and be receiving the same amount of light roughly as someone standing on the ground because we are so far away from the sun, right? Not even close to sky. One point, yeah, 146 million kilometers away, yeah. But that's the best I could do on Microsoft Word. So that's why somebody, oh, sorry, yeah. So that's why in Toy Story 4, the light, you can see they're using the correct lamp source, sunlight. So there's no fall-off regardless of where you are. So the floor is hitting the same amount as the light and other light sources, of course, using a point or an area light. It's pretty simple, but it's more so important for when you're thinking about lighting a scene. So let's say, for example, you've got a character who is lit from a lamp source, right, with that distance away. Now, you can see that most of the character is really falling within the same sort of light amount, right, even that distance away. Now, if you wanted the attention to be on the character's face, which you might if it's a character, that's where the eyes generally should go, you know, some people might take it into Photoshop and do a bunch of masking. But if you know about light fall-off, you'd know all you have to do is bring the lamp source in closer, closer to the character, and you'll naturally get that fall-off. You can see the difference that it makes to composition. So that's what it can do to your lighting when you understand fall-off. Next up, understanding light size. The smaller the light source is, the sharper that shadow is and the deeper those shadows become, revealing all the small details in the crow's feet in your eye, the little pimples and all the little imperfections, not good for faces. Whereas larger light sources, like an overcast sky, does the opposite, hiding blemishes, and it's generally much more pleasant for faces, which is why Hollywood loves to shoot with soft, large lighting. Even for outdoor shots where it doesn't make sense, they wanna use that soft lighting because it just looks so much better. Toy Story alternates between them. Hard light source for outdoor shots and then soft lighting where it makes sense to. And also, it's important to note that this is relative to the distance of the character. So this looks like a small light source. But if you brought that light source closer to the character, it does the exact same thing as if you were to make it larger. So smaller, larger, and that's just by changing the distance. So keep that in mind when you're thinking of lighting. It's like if you've got the position off and it's a large light source, it'll appear small. But if you've got it closer, a smaller point lamp will appear large, if that makes sense. So that's light. If you wanna learn some more, I've got a whole series on YouTube. You can look it up, Lighting for Beginners, and I go into much more detail there. Next, materials, my favorite topic. When light hits a material, a couple of things happen. First, some of the light is reflected. And you know it's a reflection because when you move your head left and right, you can see that the light moves with it. Some of the, the rest of the light is absorbed. It goes into the material, and then it hits some particles, and then it like bounces off those, hits some more particles, and then some of that exits the material. And that is what is called refraction, or as we 3D artists call it, diffuse. Scientists call it refraction, we call it diffuse, but it's the same thing. It's the color information. And that's pretty easy to understand. A red car is red, a green car is green, but it's reflection where a lot of people get confused because we tend to think of there being two types of objects, reflective objects and non-reflective objects. When in actual fact, they reflect the same. Most objects reflect the exact same amount. It's the sharpness of the reflection that differs. On a very smooth surface, the reflection is bouncing off in mostly the same direction it was received, whereas on a rough surface, those bounces are going to be every which way, which means the reflection is so smooth that your eye almost doesn't see it. So take, for example, a really porous object, one that you might not think has any reflection, a brick. Looks like there's no reflection. But actually at Polygon, when we're photo scanning an object, we use what's called a cross-polarized lighting setup, which means that you put a polarizing filter on the camera lens and the light source, and then it can actually cancel out a reflection. And you can see the difference in color there. And what's interesting is you can actually use a difference pass in Photoshop, and you can see what the raw reflection of that brick is. And here's another one, since I find it fascinating. This is a rock, right? Doesn't look like there's any reflection at all. This is a cross-polarized rock. Stark difference, and then there's the reflection. So every object, even ones that don't look like they are reflecting, are reflecting in roughly the same amount, which is why you should never do this. Bad. Bad. Always keep it at 0.5%. If you wanna make something look non-reflective, just crank up the roughness. It might seem like it doesn't make a difference, but it does, because all objects are reflective, it's just they have different roughness. You can see it here, little example from Toy Story. This ground doesn't look very reflective. You can see from the top there is actually some reflection. I don't know if you can tell in that picture. But all the objects, especially in this attic scene, everything has got same amounts of reflection. What's interesting, though, about reflection, it's not uniform across it. There's such a thing as Fresnel. So the edges of an object is always reflecting 100%, roughly. So like the edge of my face, if you could see the 90% angle, sorry, 90 degree angle, you would see 100% reflection. And yeah, here's an example from Toy Story. You can see that lamp there starts off very bright and then tapers in. And here's another more obvious example from George Clooney's helmet. So this is, again, why you want to be careful when you're dealing with mix shaders and that. It won't have the Fresnel. So stick to principled. I might as well just call this presentation stick to principled. It also, when you're using principled shader, it'll also adjust the Fresnel depending on how much roughness the object does, which is something you don't get if you're also trying to make something yourself. So principled shader does it all for you. Now, what I've been talking about now is really just non-metals. It gets a little different when you talk about metals. I'm sure a lot of you have heard of this, but just to rehash, metals are pure reflection. That part there where it enters into it, it does not refract any of that light. It does absorb, some of the light is absorbed into it, but that is just transferred as heat. So when you're looking at a metallic object, you are looking at purely reflective information. There is no diffuse, there is no color information there whatsoever. Metals are also the only material that will tint a reflection. Whereas every other object will be basically reflecting the color of the source lamp, basically. So the wood on that clock there will have a different color than the gold, obviously, which is tinting that reflection. But just to make it more complex, the tint will weaken with Fresnel. So towards the edges of a metallic object, it will also weaken. So that's why, really, if you're trying to make a metal object yourself, you can really screw it up quite easily. So again, stick to principle. So much easier. You just set it, crank up the metallic, change whatever roughness you want, automatically does the weakening of the Fresnel, make sure there's no diffuse, and it just looks correct. And finally, we've got variance, the most interesting part. Because if you've ever been observing the real world, you might notice, looking at objects, that it's not the same amount of gloss or bump or roughness across it. It's different, right? This road here, you've got different amounts of gloss or roughness across it, which creates these little glinting effects. There's a couple of tire tracks there, even an ice cream, right? Every object has varied amounts of these values. And this is really what gives Toy Story its rich world. Every object has different amounts of layering on it, like this sticky surface of this caravan roof, the side of this cupboard here. All of these details help to bring life to these materials while still looking quite stylized. Now, I don't know if this video is gonna play. It might stop. Let's find out. Yeah, it stopped. Can we go to that? Yeah, there we go. There's an issue with PowerPoint where it doesn't play. But anyways, you can see. So when you're just playing with the roughness, you only get a certain amount of realism. Whereas if you just plug in a noise texture, right, which takes that value and puts it between like a random range between zero and one, and then you plugged that into the roughness, I think it will continue playing. That's good. You'll see the difference that it makes. Just this one small thing, just adding variance across the surface, breathes so much more light into the realism of a material then you could plug that into the color information. You could plug that into the bump information. And then you very quickly get a much more complex realistic material. Now this is procedural. Like there's only so far you can go with a procedural material. It really comes together when you start using PBR texture sets, which are texture sets designed to go together. So the color information matches the gloss information, matches the bump information. So it all is designed to work together. Number of websites you can get PBR texture sets from. The best one just happens to be my own company. It's a coincidence. I flew from Australia. I got to make it worth my while. So that's materials. Now, moving on to the optics. This is about emulating what the camera sees, and it's very important. And the most crucial part understanding is exposure. Something that almost no one talks about, but I believe is actually the key to what makes Toy Story 4 look so real. If you've ever tried to take a photograph of someone on holiday, and you've had them standing against a bright background, and then you're like on your phone, you push on their face to make it focus, and then it blows out the background, right? That is exposure. You cannot expose for a bright object and a dark object within the same photograph. It's just impossible without HDR post-processing. So that is exposure. That's why if you've got a character sitting in front of a window, the most realistic thing you can do is blow out the window, because that is what happens in the real world. It cannot expose for both things. If you've got a room, which is a dark room with sunlight streaming in through one window, the sunlight should be clipping because it cannot expose for a dark room and the sunlight. One of them has to look wrong because that is exactly what it does in the real world with a real photograph. And this is where I think Toy Story 4 really shines. There's this great scene at the start where Woody's looking at Bo Peep, it's a very dark environment, so it's overexposed for the dark environment. And then a car headlights go across his face and it just clips, you know, like it should in the real world. And there's a whole scene where it takes place in the attic, which is a very dark and dingy environment. But then there's these sunbeams which like beat through the cracks in the roof. And like a more, I don't know, reserved or like less courageous director might try to like art direct that and go like, oh, we got to like turn down the brightness there and like bump up the shadows and try and even it out, but they let it clip. And I think that is really what helps Toy Story feel real. And you can see it across the movie, underexposed areas with bright spots that really blow out just like it would with a real camera. Any photographers in the room? People know cameras? Yeah, you already know about this, but it's called the exposure triangle. So exposure is the result of these three settings in a camera. And although we are dealing with a virtual camera with Blender, you don't need to necessarily understand all this, but you should because these do different things to the image. So the first one is aperture, right? When you're a photographer and you want to let more light into the lens, you would use a higher, no, a lower aperture. I always get, it's a smaller, larger aperture, but a smaller f-stop will let in more light, but it will also increase the, you call the depth of field, right? So it blows out the foreground, it blows out the background a lot more. And creatively, this is used for portrait photography. You like to use a lower f-stop, whereas a landscape shot, you want to use a higher f-stop so more things are in focus. And this is quite easy to do in Blender. All you need to do is select your camera. It's stopped again. Could you go to the next bit? Yeah, this is fun. Turn on depth of field, select the object you want to be in focus, and then adjust the f-stop and that's it. Blender calculates the rest for you. But what no one talks about is the fact that it is scale dependent. So if you were dealing with a very small scene, like an ant-sized miniature, look at the depth of field, so much more. Whereas if you were dealing with a larger, like city scale, the depth of field is almost imperceptible, right? So this is the same aperture. So this is why I answer when people say, why do you talk about modeling things in real-world scale? This is why. Because if you don't, I mean, first of all, if you're bringing in objects from other areas, it's just annoying to work with, everything's a different scale. But when you use the correct scale for a scene, the real-world scale, everything just works. And then when you render it, things look the way they should. Now this is actually an area where Toy Story takes some creative liberties. I was talking to Jonathan Lackstone, I don't know if he's here, yesterday, but he was like, they do kind of change the depth of field. So like some of them, they get right, like this is a miniature, correct scale for like a miniature set. But because it's dealing with toys, you could never really get two toys talking to each other if you had the real-world depth of field. So they kind of alternate it across the scene. They kind of increase it to make it look like a larger set so you can actually get more characters in focus. But much better than Toy Story 1, which I realized, like looking at it now, it's like, yeah, there's no depth of field in this shot. Like the stars are in focus. I was like, yeah, how about that? It's really weird. Like some of the shots have depth of field and others don't. It's really interesting. But anyway, by the way, who's old enough to remember like the old fashioned way of doing depth of field in Blender? We had like a curve circle. You put the camera on the curve and then it like goes around really fast. So it creates the depth of field. It's crazy. That was the old method. It's terrible. By the way, if you look at that, what was that? This bokeh here, right? This blurry area. You see those stretched, that stretched appearance there? That's emulating an anamorphic lens, which is typically used for high-end Hollywood shoots, which basically shoots at twice the width resolution-wise and then is compressed back in post-processing to the correct amount, which means that the bokeh basically appears stretched. And if you wanted to create that in Blender, very simple, that ratio amount there, you just set it to two. So it's a little hack if you want to make something look cinematic, you can just like stretch it. It's pretty easy. Shutter speed. So this one's pretty easy to understand. Everyone sort of intuitively gets it. The longer a shutter speed is open, the more light is going to be hitting the lens, but the more motion blur there is basically in the scene. So in Blender, there's really just one setting, you turn on motion blur, and then you've got a shutter value there. So that shutter value is really just, I don't know, what would you call it? Just made up? It doesn't really match anything. So it's really up to you as to how much motion blur there is. So this is where understanding cameras can come in to play because really there would be a higher motion blur when you need more light to hit the lens. So a daytime scene, there would generally be less motion blur than a nighttime one. This one, I think there's quite a lot because it's coming towards the camera. But yeah, generally nighttime shots, there is a higher shutter speed in order to get more light to hit the lens, whereas a daytime one, there is less. By the way, fun fact, the ornithopters in Dune, the wings are beating at supersonic speed so fast that they couldn't actually calculate the motion blur. So they had to render 11 subframes just to get the motion blur. So basically every single frame there is rendered 11 times just to get the motion blur to look right, which is really cool. And then finally, you've got grain, or as I call it like the last attempt to get more light at the sensor. Basically, the higher the ISO on a camera, the more light is sort of forced onto it, forced onto the sensor. So it's a quick way to basically, yeah, get more light in there without having to deal with motion blur and all that. But you do get more noise with that. However, it's not just one type of noise. There is digital noise and there is film grain. And it's sort of fiercely debated in the camera world. Basically digital noise generally looks colorless. It is pixel sized and generally uneven. So it's more obvious to your eye. Whereas film is more grayscale, varying sizes and it's more uniform. So it's generally much more pleasing for your eye. Now, if you're hearing this and you're thinking, oh great, so like grain and noise is a good thing. Because my scenes are very noisy. I'll just do a couple of samples and call it a day. No. The grain or the noise that comes with a path trace render engine is completely different to film or camera noise. Path tracing is throwing samples at areas in order to clear it up. But some areas are gonna be less. Maybe you've got like a small light source or something refracting through a glass. And that's gonna be noisy. Other areas are gonna be clean. It's gonna be all over the shop. It's never gonna look right. So basically noise from a render engine is completely different to grain from film. So basically you should be trying to render out as many samples as you can, cleaning up the shot with denoising and then adding grain over the top, which you can do in Photoshop. Or you could use for animation like a plugin like Red Giant's Renoiser. Or if you really wanna go on the cheap side, you could just get a camera, put the lens cap on, record like 10 seconds of it. And then like throw that over as an overlay in Premiere. The other thing also quickly as a bonus is barrel distortion for lenses. So towards the edges of a lens, you typically get like bowing out of straight lines, like over there. And that is done very easily in Blender using a lens distortion node in the compositor and increasing some distortion. You can also do it with a camera like panamorphic, but this is just way easier. And you can see there's a little bit on the edge of some of the wide shots in Toy Story 4. And then also glare as well. Really important, basically whenever the camera is receiving hard light, but it has to be exposed for a darker scene, that bright light on that small part of it is kind of, the way I think of it, it's like fuzzy in that area. Like the sensor can't really clean it up. So that is perceived as glare. And that appears not just in dark scenes, but also in sunlit scenes where you've got dark and bright together. You will get that glare. And that is very easy to do with a glare node. You just set it to streaks or glow depending on what you want. So that is basically it, the light, the materials and the optics. So in the 20 years since the release of the first movie, hardware got beefier, 3D software got more accurate, yes. But what makes the movie realistic is actually restraint because despite existing in a world with talking toys, it adheres to the principles of photorealism more than most movies, which in my opinion makes it one of the most pleasant, fun movies of the last few years and definitely the most beautiful. So thank you all for listening. Thank you. Thank you.  